from __future__ import annotations
import streamlit as st
from app.lib.auth import login, show_logout
# === Auth (auto-injected) ===
import streamlit as st  # ensured
from app.lib.auth import login, show_logout

auth = login(required=False)   # or required=True for protected pages
if not auth.authenticated:
    st.info("You are in read-only mode.")
show_logout()  # sidebar logout
# === /Auth (auto-injected) ===
from __future__ import annotations
import streamlit as st
# --- import bootstrap so 'app' package is importable when run from anywhere ---
import sys
from pathlib import Path
_HERE = Path(__file__).resolve()
# file: .../serving_ui/app/pages/<page>.py  -> parents[2] = .../serving_ui
_SERVING_UI = _HERE.parents[2]
if str(_SERVING_UI) not in sys.path:
    sys.path.insert(0, str(_SERVING_UI))

from app.lib.access import live_enabled

if live_enabled():
    # do live fetch / recompute / write / API calls
    do_expensive_refresh()
else:
    # skip; rely on cached CSVs in /exports that your app already loads
    pass
# -----------------------------------------------------------------------------
import streamlit as st
st.set_page_config(page_title='96 Compare Models', page_icon='ðŸ“ˆ', layout='wide')

import streamlit as st

import streamlit as st


import streamlit as st

# --- diagnostics import (robust) ---
try:
    from app.utils.diagnostics import mount_in_sidebar
except ModuleNotFoundError:
    try:
        import sys
        from pathlib import Path as _efP
        # add repo/serving_ui to sys.path so 'app' is importable
        sys.path.append(str(_efP(__file__).resolve().parents[3]))
        from app.utils.diagnostics import mount_in_sidebar
    except Exception:
        try:
            # fallback if pages run with CWD=app
            from utils.diagnostics import mount_in_sidebar
        except Exception:
            def mount_in_sidebar(page_name: str):
                return None
# --- /diagnostics import (robust) ---
# serving_ui/app/pages/96_Compare_Models.py

import math
from pathlib import Path
from typing import Dict, Any, Iterable

import numpy as np
import pandas as pd
import streamlit as st

# ------------- Page setup -------------
st.title("ðŸ“Š Compare Models")

BUILD_TAG = "compare-models-v2"

# ------------- Helpers -------------
def _project_root() -> Path:
    here = Path(__file__).resolve()
    # .../serving_ui/app/pages/96_Compare_Models.py -> project root a few parents up
    for p in [here.parents[3], here.parents[2], here.parents[1]]:
        if (p / "exports").exists():
            return p
    return here.parents[3] if len(here.parents) >= 4 else Path.cwd()

def _exports_dir() -> Path:
    root = _project_root()
    exp = root / "exports"
    exp.mkdir(parents=True, exist_ok=True)
    return exp

def _safe_str_cols(df: pd.DataFrame, cols: Iterable[str]) -> pd.DataFrame:
    out = df.copy()
    for c in cols:
        if c in out.columns:
            out[c] = out[c].astype(str)
    return out

def _to_series(x) -> pd.Series:
    """Normalize scalars/arrays/Series/DataFrames to a 1D float Series."""
    if isinstance(x, pd.Series):
        return pd.to_numeric(x, errors="coerce")
    if isinstance(x, pd.DataFrame):
        if x.shape[1] == 0:
            return pd.Series([], dtype="float64")
        return pd.to_numeric(x.iloc[:, 0], errors="coerce")
    if np.isscalar(x) or x is None:
        # single-element Series for scalars/None
        return pd.Series([x], dtype="float64")
    # list/tuple/np array, etc.
    return pd.to_numeric(pd.Series(x), errors="coerce")

def american_to_decimal(odds: Any) -> float | np.nan:
    """Convert American odds to decimal payout multiplier (incl. stake)."""
    try:
        o = float(odds)
    except Exception:
        return np.nan
    if math.isnan(o):
        return np.nan
    if o > 0:
        return 1.0 + (o / 100.0)
    if o < 0:
        return 1.0 + (100.0 / abs(o))
    return np.nan

def add_probs_and_ev(df: pd.DataFrame) -> pd.DataFrame:
    """Best-effort: ensure p_win, payout_decimal, _ev_per_$1 exist."""
    out = df.copy()

    # p_win candidates
    p_candidates = ["p_win", "prob", "p", "prob_win", "win_prob"]
    p = None
    for c in p_candidates:
        if c in out.columns:
            p = pd.to_numeric(out[c], errors="coerce").clip(0, 1)
            break
    if p is None:
        out["p_win"] = np.nan
    else:
        out["p_win"] = p

    # payout candidates (decimal). If only American odds exist, convert.
    dec_candidates = ["_payout_decimal", "payout_decimal", "decimal_odds", "payout"]
    amer_candidates = ["american_odds", "odds", "american"]

    dec = None
    for c in dec_candidates:
        if c in out.columns:
            dec = pd.to_numeric(out[c], errors="coerce")
            break

    if dec is None:
        amer = None
        for c in amer_candidates:
            if c in out.columns:
                amer = out[c]
                break
        if amer is not None:
            out["_payout_decimal"] = pd.to_numeric(amer, errors="coerce").map(american_to_decimal)
        else:
            out["_payout_decimal"] = np.nan
    else:
        out["_payout_decimal"] = dec

    # EV per $1 = p_win * payout_decimal - (1 - p_win)
    p = pd.to_numeric(out.get("p_win"), errors="coerce")
    d = pd.to_numeric(out.get("_payout_decimal"), errors="coerce")
    out["_ev_per_$1"] = (p * d) - (1.0 - p)
    return out

def ev_metrics(df_like: Dict[str, Any] | pd.DataFrame) -> Dict[str, Any]:
    """Compute robust EV metrics from dict-like or DataFrame row/columns."""
    get = (df_like.get if hasattr(df_like, "get") else (lambda k, default=None: getattr(df_like, k, default)))

    p = _to_series(get("p_win", np.nan))
    payout = _to_series(get("_payout_decimal", get("payout_decimal", get("payout", np.nan))))
    ev = _to_series(get("_ev_per_$1", get("ev", np.nan)))

    n = int(len(p))
    with_p = int(p.notna().sum())
    with_payout = int(payout.notna().sum())
    with_ev = int(ev.notna().sum())

    ev_mean = float(ev.mean(skipna=True)) if with_ev else float("nan")
    ev_median = float(ev.median(skipna=True)) if with_ev else float("nan")
    ev_pos = int((ev > 0).sum()) if with_ev else 0
    ev_nonneg = int((ev >= 0).sum()) if with_ev else 0
    ev_p95 = float(ev.quantile(0.95)) if with_ev else float("nan")
    ev_p05 = float(ev.quantile(0.05)) if with_ev else float("nan")

    return {
        "rows": n,
        "with_p": with_p,
        "with_payout": with_payout,
        "with_ev": with_ev,
        "ev_mean": ev_mean,
        "ev_median": ev_median,
        "ev_p95": ev_p95,
        "ev_p05": ev_p05,
        "ev_pos": ev_pos,
        "ev_nonneg": ev_nonneg,
    }

def summarize_by(df: pd.DataFrame, by: str) -> pd.DataFrame:
    """Group by a model column and compute EV metrics per group."""
    if by not in df.columns:
        return pd.DataFrame(columns=["model","rows","with_p","with_payout","with_ev","ev_mean","ev_median","ev_p95","ev_p05","ev_pos","ev_nonneg"])

    recs = []
    for model_name, g in df.groupby(by, dropna=False):
        met = ev_metrics(g)
        recs.append({"model": str(model_name), **met})
    out = pd.DataFrame(recs).sort_values(["ev_mean","with_ev","rows"], ascending=[False, False, False], na_position="last")
    return out

# ------------- Data loading -------------
exp = _exports_dir()

st.caption(f"Build: `{BUILD_TAG}` Â· exports: `{exp}`")

# Try common files; user can override with file_uploader
default_candidates = [
    exp / "edges_models.csv",
    exp / "edges_graded_plus.csv",
    exp / "edges_graded_full.csv",
    exp / "predictions.csv",
]

path_found = next((p for p in default_candidates if p.exists()), None)

left, right = st.columns([2, 1])
with left:
    st.write("**Source**")
    src_choice = st.radio(
        "Pick a source file",
        ["Auto-detected", "Upload CSV"],
        captions=["Use first existing default", "Upload a custom file"],
        label_visibility="collapsed",
        horizontal=True,
    )
    uploaded = None
    if src_choice == "Upload CSV":
        uploaded = st.file_uploader("Upload model predictions CSV", type=["csv"], accept_multiple_files=False)
    else:
        if path_found:
            st.caption(f"Auto: `{path_found}`")
        else:
            st.warning("No default file found in exports/. Upload a CSV.")

with right:
    st.write("**Model column**")
    model_col = st.text_input("Model name column", value="_model", help="Name of the column that identifies the model for each row.")
    st.write("**Probability column**")
    prob_col = st.text_input("p_win column", value="p_win", help="Probability of the pick winning (0..1).")
    st.write("**Payout column**")
    payout_col = st.text_input("Decimal payout column", value="_payout_decimal", help="Decimal odds incl. stake; leave if will be derived.")
    st.write("**American odds column (fallback)**")
    american_col = st.text_input("American odds column", value="american_odds", help="If decimal payout missing, this will be converted.")

# Load the dataframe
df: pd.DataFrame
try:
    if uploaded is not None:
        df = pd.read_csv(uploaded, low_memory=False)
    elif path_found:
        df = pd.read_csv(path_found, low_memory=False)
    else:
        df = pd.DataFrame()
except Exception as e:
    st.error(f"Failed to read CSV: {e}")
    st.stop()

if df.empty:
    st.info("No data loaded yet.")
    st.stop()

# Normalize and compute EV
df = add_probs_and_ev(df)

# If custom column names were given that differ, adapt to our expected names.
if prob_col in df.columns and prob_col != "p_win":
    df["p_win"] = pd.to_numeric(df[prob_col], errors="coerce").clip(0, 1)
if payout_col in df.columns and payout_col != "_payout_decimal":
    df["_payout_decimal"] = pd.to_numeric(df[payout_col], errors="coerce")
if american_col in df.columns and df["_payout_decimal"].isna().all():
    df["_payout_decimal"] = pd.to_numeric(df[american_col], errors="coerce").map(american_to_decimal)

# Ensure model column exists
if model_col not in df.columns:
    # Try common alternates
    for alt in ["model", "model_name", "algo", "_model_name"]:
        if alt in df.columns:
            model_col = alt
            break
    else:
        df[model_col] = "unknown"

# ------------- UI: Filters -------------
with st.expander("Filters", expanded=False):
    leagues = None
    if "_league" in df.columns:
        leagues = sorted([x for x in df["_league"].dropna().astype(str).unique()])
        chosen_leagues = st.multiselect("League(s)", leagues, default=leagues[:4] if leagues else None)
        if chosen_leagues:
            df = df[df["_league"].astype(str).isin(chosen_leagues)]

    min_p = st.slider("Min p_win", 0.0, 1.0, 0.00, 0.01)
    max_p = st.slider("Max p_win", 0.0, 1.0, 1.00, 0.01)
    df = df[df["p_win"].between(min_p, max_p, inclusive="both")]

    if "_ev_per_$1" in df.columns:
        min_ev = st.slider("Min EV per $1", -1.0, 2.0, -1.0, 0.01)
        df = df[df["_ev_per_$1"] >= min_ev]

# ------------- Summaries -------------
overall = ev_metrics(df)
st.subheader("Overall")
c1, c2, c3, c4, c5, c6, c7 = st.columns(7)
c1.metric("Rows", f"{overall['rows']:,}")
c2.metric("With p", f"{overall['with_p']:,}")
c3.metric("With payout", f"{overall['with_payout']:,}")
c4.metric("With EV", f"{overall['with_ev']:,}")
c5.metric("EV mean", f"{overall['ev_mean']:.4f}" if not math.isnan(overall["ev_mean"]) else "â€”")
c6.metric("EV median", f"{overall['ev_median']:.4f}" if not math.isnan(overall["ev_median"]) else "â€”")
c7.metric("EV p95", f"{overall['ev_p95']:.4f}" if not math.isnan(overall["ev_p95"]) else "â€”")

st.subheader("By Model")
by_model = summarize_by(df, model_col)
st.dataframe(by_model, use_container_width=True)

# ------------- Detail view -------------
with st.expander("Sample Rows (cleaned view)", expanded=False):
    cols_show = [c for c in ["_league", model_col, "p_win", "_payout_decimal", "_ev_per_$1", "american_odds"] if c in df.columns]
    st.dataframe(df[cols_show].head(100), use_container_width=True)

# ------------- Export -------------
colA, colB = st.columns(2)
with colA:
    st.download_button(
        "Download per-model summary (CSV)",
        by_model.to_csv(index=False).encode("utf-8"),
        file_name="compare_models_summary.csv",
        mime="text/csv",
        use_container_width=True,
    )
with colB:
    st.download_button(
        "Download filtered rows (CSV)",
        df.to_csv(index=False).encode("utf-8"),
        file_name="compare_models_filtered.csv",
        mime="text/csv",
        use_container_width=True,
    )

st.caption(f"âœ” Ready Â· {len(df):,} rows after filters Â· model column: `{model_col}`")








