from __future__ import annotations

# --- import bootstrap so 'app' package is importable when run from anywhere ---
import sys, os
from pathlib import Path
_HERE = Path(__file__).resolve()
_SERVING_UI = _HERE.parents[2]  # .../serving_ui
if str(_SERVING_UI) not in sys.path:
    sys.path.insert(0, str(_SERVING_UI))
from app.lib.access import require_allowed_page, beta_banner
require_allowed_page("pages/09_All_Picks_Explorer.py")
beta_banner()
from app.lib.access import live_enabled

if live_enabled():
    # do live fetch / recompute / write / API calls
    do_expensive_refresh()
else:
    # skip; rely on cached CSVs in /exports that your app already loads
    pass

# -----------------------------------------------------------------------------
import streamlit as st
import streamlit as st
st.set_page_config(page_title='09 All Picks Explorer', page_icon='ðŸ“ˆ', layout='wide')

import streamlit as st

import streamlit as st


import streamlit as st


import os, time, math
from pathlib import Path
from typing import List, Optional, Dict
import numpy as np
import pandas as pd
import streamlit as st
from app.utils.parlay_ui import selectable_odds_table
from app.utils.parlay_cart import read_cart, clear_cart
# --- diagnostics import (robust) ---
try:
    from app.utils.diagnostics import mount_in_sidebar
except ModuleNotFoundError:
    try:
        import sys
        from pathlib import Path as _efP
        # add repo/serving_ui to sys.path so 'app' is importable
        sys.path.append(str(_efP(__file__).resolve().parents[3]))
        from app.utils.diagnostics import mount_in_sidebar
    except Exception:
        try:
            # fallback if pages run with CWD=app
            from utils.diagnostics import mount_in_sidebar
        except Exception:
            def mount_in_sidebar(page_name: str):
                return None
# --- /diagnostics import (robust) ---

TZ = "America/New_York"

def _exports_dir() -> Path:
    env = os.environ.get("EDGE_EXPORTS_DIR", "").strip()
    if env:
        p = Path(env); p.mkdir(parents=True, exist_ok=True); return p
    here = Path(__file__).resolve()
    for up in [here.parent] + list(here.parents):
        if up.name.lower() == "edge-finder":
            p = up / "exports"; p.mkdir(parents=True, exist_ok=True); return p
    p = Path.cwd() / "exports"; p.mkdir(parents=True, exist_ok=True); return p

def _age_str(p: Path) -> str:
    try:
        secs = int(time.time() - p.stat().st_mtime)
        return f"{secs}s" if secs < 60 else f"{secs//60}m"
    except Exception:
        return "n/a"

_ALIAS = {
    "REDSKINS": "COMMANDERS", "WASHINGTON": "COMMANDERS", "FOOTBALL": "COMMANDERS",
    "OAKLAND": "RAIDERS", "LV": "RAIDERS", "LAS": "RAIDERS", "VEGAS": "RAIDERS",
    "SD": "CHARGERS", "STL": "RAMS",
}

def _nickify(series: pd.Series) -> pd.Series:
    s = series.astype("string").fillna("").str.upper()
    s = s.str.replace(r"[^A-Z0-9 ]+", "", regex=True).str.strip().replace(_ALIAS)
    return s.str.replace(r"\s+", "_", regex=True)

def _best_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    low = {c.lower(): c for c in df.columns}
    for c in candidates:
        if c.lower() in low: return low[c.lower()]
    return None

def _ensure_nicks(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty: return df
    home_c = _best_col(df, ["_home_nick","home_nick","home","home_team","Home","HOME","team_home"])
    away_c = _best_col(df, ["_away_nick","away_nick","away","away_team","Away","AWAY","team_away"])
    if home_c is None: df["_home_nick"] = pd.Series([""]*len(df), dtype="string")
    else: df["_home_nick"] = _nickify(df[home_c].astype("string"))
    if away_c is None: df["_away_nick"] = pd.Series([""]*len(df), dtype="string")
    else: df["_away_nick"] = _nickify(df[away_c].astype("string"))
    return df

def _norm_market(m) -> str:
    m = (str(m) or "").strip().lower()
    if m in {"h2h", "ml", "moneyline", "money line"}: return "H2H"
    if m.startswith("spread") or m in {"spread", "spreads"}: return "SPREADS"
    if m.startswith("total")  or m in {"total", "totals"}:  return "TOTALS"
    return m.upper()

def _odds_to_decimal(o: pd.Series) -> pd.Series:
    o = pd.to_numeric(o, errors="coerce")
    return np.where(o > 0, 1 + (o / 100.0),
           np.where(o < 0, 1 + (100.0 / np.abs(o)), np.nan))

def _ensure_date_iso(df: pd.DataFrame, candidates: List[str]) -> pd.DataFrame:
    if len(df) == 0: return df
    for c in candidates:
        if c in df.columns:
            s = pd.to_datetime(df[c], errors="coerce", utc=True)
            df["_date_iso"] = s.dt.tz_convert(TZ).dt.strftime("%Y-%m-%d")
            break
    if "_date_iso" not in df.columns:
        df["_date_iso"] = pd.Series(pd.NA, index=df.index, dtype="string")
    return df

def latest_batch(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty: return df
    for col in ["_snapshot_ts_utc","snapshot_ts_utc","snapshot_ts","_ts","ts"]:
        if col in df.columns:
            ts = pd.to_datetime(df[col], errors="coerce", utc=True)
            last = ts.max()
            return df[ts == last].copy()
    return df

def within_next_week(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty: return df
    if "_date_iso" not in df.columns: return df
    d = pd.to_datetime(df["_date_iso"], errors="coerce", utc=True).dt.tz_convert(TZ)
    today = pd.Timestamp.now(tz=TZ).normalize()
    end   = today + pd.Timedelta(days=7)
    return df[(d >= today) & (d <= end)].copy()

def refresh_button(key: Optional[str] = None):
    if st.button("ðŸ”„ Refresh data", key=key or f"refresh_{__name__}"):
        try: st.cache_data.clear()
        except Exception: pass
        st.rerun()

def _latest_csv(paths: list[Path]) -> Optional[Path]:
    paths = [p for p in paths if p and p.exists()]
    if not paths: return None
    return max(paths, key=lambda p: p.stat().st_mtime)

@st.cache_data(ttl=60)
def load_live() -> tuple[pd.DataFrame, Path]:
    exp = _exports_dir()
    cand = [exp / "lines_live.csv", exp / "lines_live_latest.csv"]
    p = _latest_csv(cand) or cand[0]
    df = pd.read_csv(p, low_memory=False, encoding="utf-8-sig") if p.exists() else pd.DataFrame()
    return df, p

@st.cache_data(ttl=60)
def load_open_close() -> tuple[pd.DataFrame, Path]:
    exp = _exports_dir()
    cand = [exp/"lines_open_close.csv", exp/"lines_open_close_latest.csv"]
    p = _latest_csv(cand) or cand[0]
    df = pd.read_csv(p, low_memory=False, encoding="utf-8-sig") if p.exists() else pd.DataFrame()
    return df, p

@st.cache_data(ttl=60)
def load_edges() -> tuple[pd.DataFrame, Path]:
    exp = _exports_dir()
    names = ["edges_standardized.csv","edges_graded_full_normalized_std.csv","edges_graded_full.csv","edges_normalized.csv","edges_master.csv"]
    paths = [exp/n for n in names]
    p = _latest_csv(paths) or paths[0]
    df = pd.read_csv(p, low_memory=False, encoding="utf-8-sig") if p.exists() else pd.DataFrame()
    return df, p

diag = mount_in_sidebar("09_All_Picks_Explorer")
st.title("All Picks â€” Explorer")
refresh_button(key="refresh_09_all_picks")

live, live_path = load_live()
edges, edges_path = load_edges()
st.caption(f"Live lines: `{live_path}` Â· rows={len(live):,} Â· age={_age_str(live_path)}")
st.caption(f"Edges: `{edges_path}` Â· rows={len(edges):,}")

edges = _ensure_date_iso(edges, ["_date_iso","date","game_date","_key_date","Date"])
live  = _ensure_date_iso(live,  ["_date_iso","event_date","commence_time","date","game_date","Date"])
edges = _ensure_nicks(edges); live = _ensure_nicks(live)

edges["_market_norm"] = edges.get("_market_norm", edges.get("market", pd.Series(index=edges.index))).map(_norm_market)
live["_market_norm"]  = live.get("_market_norm",  live.get("market",  pd.Series(index=live.index))).map(_norm_market)

snap_live = within_next_week(latest_batch(live))

st.sidebar.header("Filters")
books  = st.sidebar.multiselect("Books", sorted(snap_live.get("book", pd.Series(dtype='string')).dropna().unique()))
mkts   = st.sidebar.multiselect("Markets", sorted(snap_live.get("_market_norm", pd.Series(dtype='string')).dropna().unique()), default=["H2H","SPREADS","TOTALS"])
teams  = st.sidebar.text_input("Team contains (nick)", "").strip().upper()

q = snap_live.copy()
if books: q = q[q.get("book", pd.Series(index=q.index)).isin(books)]
if mkts:  q = q[q.get("_market_norm", pd.Series(index=q.index)).isin(mkts)]
if teams:
    q = q[q["_home_nick"].str.contains(teams, na=False) | q["_away_nick"].str.contains(teams, na=False)]

cols = [c for c in ["_date_iso","_home_nick","_away_nick","_market_norm","side","line","price","decimal","book"] if c in q.columns]
sort_by = [c for c in ["_date_iso","_home_nick","book","_market_norm","side"] if c in q.columns]
st.write(f"Showing {len(q):,} rows")
st.dataframe(q[cols].sort_values(sort_by), use_container_width=True, hide_index=True)

# --- _EF_DIAG_SNAPSHOT_ (auto-added) ---
try:
    import pandas as _ef_pd
    from pathlib import Path as _ef_Path
    _ef = locals().get("diag", None)
    if _ef:
        for _nm in ("edges_p","live_p","oc_path","edges_path","live_path","scores_path","scores_p","epath","spath","_lines_p","_edges_p"):
            _p = locals().get(_nm, None)
            if _p:
                try: _ef.check_file(_ef_Path(str(_p)), required=False, label=_nm)
                except Exception: pass
        for _dfn in ("edges","live","oc","scores","joined","view"):
            _df = locals().get(_dfn, None)
            try:
                if isinstance(_df, _ef_pd.DataFrame):
                    _ef.log_df(_df, _dfn)
            except Exception:
                pass
except Exception:
    pass
# --- /_EF_DIAG_SNAPSHOT_ ---




# --- AUTO-APPENDED: add-to-cart selector ---
try:
    if "edges" in globals() and isinstance(edges, pd.DataFrame):
        selectable_odds_table(edges, page_key="all_picks_edges", page_name="09_All_Picks_Explorer")
    if "live" in globals() and isinstance(live, pd.DataFrame):
        selectable_odds_table(live, page_key="all_picks_live", page_name="09_All_Picks_Explorer")
except Exception:
    pass




