# -*- coding: utf-8 -*-
from __future__ import annotations
import os, re, numpy as np, pandas as pd
import datetime as dt
import streamlit as st
import streamlit.components.v1 as components

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Loaders (prefer lib.io_paths; fallback to local CSVs)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    from lib.io_paths import autoload_edges, autoload_lines, clear_loader_cache
except Exception:
    def _read_csv(path: str) -> pd.DataFrame:
        try: return pd.read_csv(path, low_memory=False, encoding="utf-8-sig")
        except Exception: return pd.DataFrame()
    def autoload_edges(with_caption: bool=False):
        for name in ["exports/edges_graded_full.csv","exports/edges_master.csv",
                     "exports/edges_graded.csv","exports/edges.csv"]:
            if os.path.exists(name) and os.path.getsize(name) > 256:
                df = _read_csv(name)
                if with_caption:
                    mtime = dt.datetime.fromtimestamp(os.path.getmtime(name))
                    st.caption(f"Loaded: {name} Â· rows={len(df):,} Â· cols={len(df.columns)} Â· mtime={mtime:%Y-%m-%d %H:%M:%S}")
                return df, name, os.path.abspath("exports")
        return pd.DataFrame(), None, os.path.abspath("exports")
    def autoload_lines(with_caption: bool=False):
        for name in ["exports/lines_live.csv","exports/live_lines.csv"]:
            if os.path.exists(name) and os.path.getsize(name) > 64:
                df = _read_csv(name)
                if with_caption:
                    mtime = dt.datetime.fromtimestamp(os.path.getmtime(name))
                    st.caption(f"Live lines: {name} Â· rows={len(df):,} Â· cols={len(df.columns)} Â· mtime={mtime:%Y-%m-%d %H:%M:%S}")
                return df, name, os.path.abspath("exports")
        if with_caption: st.caption("Live lines: â€”")
        return pd.DataFrame(), None, os.path.abspath("exports")
    def clear_loader_cache(): pass

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Page chrome
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="All Picks Explorer", page_icon="ðŸ§­", layout="wide")
st.title("All Picks Explorer")

with st.sidebar:
    auto = st.toggle("Auto-refresh every 30s", value=True)
if auto:
    components.html("<script>setTimeout(function(){location.reload();},30000);</script>",
                    height=0, width=0)

if st.button("Refresh data", type="primary"):
    try: clear_loader_cache()
    except Exception: pass
    st.rerun()

edges, edges_path, root_path = autoload_edges(with_caption=True)
lines, lines_path, _ = autoload_lines(with_caption=True)
if edges.empty and lines.empty: st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helpers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _as_str(s: pd.Series | None) -> pd.Series:
    if s is None: return pd.Series(dtype="object")
    return s.map(lambda x: "" if pd.isna(x) else str(x))

def american_to_decimal(odds: pd.Series) -> pd.Series:
    o = pd.to_numeric(odds, errors="coerce")
    d = pd.Series(np.nan, index=o.index, dtype="float64")
    pos, neg = o > 0, o < 0
    d.loc[pos] = 1.0 + (o.loc[pos]/100.0)
    d.loc[neg] = 1.0 + (100.0/o.loc[neg].abs())
    return d

def implied_prob(odds: pd.Series) -> pd.Series:
    o = pd.to_numeric(odds, errors="coerce")
    p = pd.Series(np.nan, index=o.index, dtype="float64")
    pos, neg = o > 0, o < 0
    p.loc[pos] = 100.0/(o.loc[pos] + 100.0)
    p.loc[neg] = (-o.loc[neg]) / ((-o.loc[neg]) + 100.0)
    return p

def ev_per_dollar(p_win: pd.Series, odds: pd.Series) -> pd.Series:
    p = pd.to_numeric(p_win, errors="coerce")
    dec = american_to_decimal(odds)
    ev = p*(dec - 1.0) - (1.0 - p)
    ev[(p.isna()) | (dec.isna()) | (dec <= 1.0)] = np.nan
    return ev

def to_nick(s: str) -> str:
    if not isinstance(s, str): return ""
    parts = re.findall(r"[A-Za-z0-9]+", s.title())
    return parts[-1] if parts else ""

def norm_market(s: pd.Series) -> pd.Series:
    v = _as_str(s).str.strip().str.lower()
    return np.select(
        [v.isin(["h2h","ml","moneyline","money line"]),
         v.isin(["spread","spreads","point spread","ps"]),
         v.isin(["total","totals","over/under","ou","o/u"])],
        ["H2H","SPREADS","TOTALS"],
        default=v.str.upper(),
    )

def build_gid(date_col: pd.Series, away_col: pd.Series, home_col: pd.Series) -> pd.Series:
    d = _as_str(date_col).str[:10].str.replace("-", "", regex=False)
    a = _as_str(away_col).map(to_nick).str.upper().str.replace(r"[^A-Z0-9]","", regex=True)
    h = _as_str(home_col).map(to_nick).str.upper().str.replace(r"[^A-Z0-9]","", regex=True)
    return (d + "_" + a.str[:12] + "_AT_" + h.str[:12]).str.strip()

def norm_date_naive(s: pd.Series) -> pd.Series:
    """Parse timestamps (aware or naive) -> UTC -> drop tz -> normalize to midnight."""
    dtv = pd.to_datetime(s, errors="coerce", utc=True)
    return dtv.dt.tz_convert(None).dt.normalize()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# EDGES: normalize & metrics
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
e = edges.copy()
for need in ["game_id","market","side","odds"]:
    if need not in e.columns: e[need] = np.nan

_date_raw = e.get("_DateISO") if "_DateISO" in e.columns else e.get("Date")
e["_date"] = norm_date_naive(_date_raw)

if "game_id" not in e.columns or e["game_id"].isna().all() or _as_str(e["game_id"]).eq("").all():
    e["game_id"] = build_gid(_date_raw, e.get("_away_team", e.get("away")),
                             e.get("_home_team", e.get("home")))

e["market_norm"] = norm_market(e["market"])
e["side_norm"]   = _as_str(e["side"]).map(to_nick)

# choose a model prob column if present (p_model, p_win, model_prob, prob)
prob_cols = [c for c in ["p_model", "p_win", "model_prob", "prob"] if c in e.columns]
if prob_cols:
    e["p_model_use"] = pd.to_numeric(e[prob_cols[0]], errors="coerce").clip(0, 1)
else:
    e["p_model_use"] = np.nan  # no model available

# keep implied prob & EV for display (if odds exist)
e["implied_p(odds)"] = implied_prob(e["odds"])
e["ev/$1"]  = ev_per_dollar(e["p_model_use"], e["odds"])
e["p_edge"] = e["p_model_use"] - e["implied_p(odds)"]

if e["_date"].notna().any():
    st.caption(f"Date range in file: {e['_date'].min():%Y-%m-%d} â†’ {e['_date'].max():%Y-%m-%d}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LINES: normalize & best house price per (game_id, market, selection)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
L = lines.copy()
house = pd.DataFrame()
if not L.empty:
    L["_date"]        = norm_date_naive(L.get("commence_time"))
    L["game_id_join"] = build_gid(L["_date"], L.get("away"), L.get("home"))
    L["market_norm"]  = norm_market(L.get("market", pd.Series()))
    L["side_norm"]    = _as_str(L.get("selection")).map(to_nick)
    L["house_odds"]   = pd.to_numeric(L.get("price_american"), errors="coerce")
    L["house_book"]   = _as_str(L.get("book"))
    L["_dec"]         = american_to_decimal(L["house_odds"])

    agg = (L.dropna(subset=["game_id_join","market_norm","side_norm","house_odds"])
             .sort_values("_dec", ascending=False)
             .drop_duplicates(subset=["game_id_join","market_norm","side_norm"], keep="first"))
    house = agg[["game_id_join","market_norm","side_norm","house_odds","house_book"]] \
            .rename(columns={"game_id_join":"game_id"})

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Include live-only games (scaffold), align columns safely
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not L.empty and not house.empty:
    live_keys = house[["game_id","market_norm","side_norm"]].drop_duplicates()
    edge_keys = e[["game_id","market_norm","side_norm"]].drop_duplicates()
    missing = (live_keys.merge(edge_keys, on=["game_id","market_norm","side_norm"],
                               how="left", indicator=True)
                        .query("_merge=='left_only'").drop(columns="_merge"))
    if not missing.empty:
        ctx = (L[["_date","game_id_join","home","away","market_norm","side_norm"]]
                 .drop_duplicates(subset=["game_id_join","market_norm","side_norm"])
                 .rename(columns={"game_id_join":"game_id"}))
        scaf = (missing.merge(ctx, on=["game_id","market_norm","side_norm"], how="left")
                       .assign(market=lambda d: d["market_norm"],
                               side=lambda d: d["side_norm"],
                               odds=np.nan,
                               **{"implied_p(odds)":np.nan, "p_model_use":np.nan,
                                  "p_edge":np.nan, "ev/$1":np.nan}))
        # ensure tz-naive date present
        today_scaf = pd.Timestamp.now(tz="UTC").tz_convert(None).normalize()
        scaf["_date"] = norm_date_naive(scaf.get("_date")).fillna(today_scaf)
        # align to edges columns
        scaf_aligned = scaf.reindex(columns=e.columns, fill_value=np.nan)
        e = pd.concat([e, scaf_aligned], ignore_index=True, sort=False)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Merge best house price into view
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
view = e.merge(house, on=["game_id","market_norm","side_norm"], how="left", validate="m:1")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Filters & scopes
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("Filters")
    sport = st.multiselect("Sport", sorted(_as_str(view.get("sport", pd.Series(dtype=str))).str.lower().dropna().unique()))
    markets = st.multiselect("Markets", sorted(view["market_norm"].dropna().unique()))
    min_ev = st.slider("Min EV per $1", -1.0, 1.0, 0.00, 0.01)
    min_edge = st.slider("Min prob edge", -0.5, 0.5, 0.00, 0.01)
    likes_only = st.toggle("Show only likes", value=False)
    has_model_only = st.toggle("Show only rows with model", value=False)
    date_mode = st.selectbox(
        "Which games?",
        ["This week (Thuâ€“Mon)", "Upcoming (>= today)", "Latest date only", "Last 3 days", "All"],
        index=0,
    )

today = pd.Timestamp.now(tz="UTC").tz_convert(None).normalize()
if date_mode == "This week (Thuâ€“Mon)":
    wd = int(today.weekday())                  # Mon=0..Sun=6
    start = (today - pd.Timedelta(days=((wd - 3) % 7))).normalize()  # Thursday
    end   = (start + pd.Timedelta(days=4)).normalize()               # Monday
    v = view[(view["_date"] >= start) & (view["_date"] <= end)]
    if v.empty and view["_date"].notna().any():
        latest = view["_date"].max(); v = view[view["_date"].eq(latest)].copy()
elif date_mode == "Upcoming (>= today)":
    v = view[view["_date"] >= today]
    if v.empty and view["_date"].notna().any():
        latest = view["_date"].max(); v = view[view["_date"].eq(latest)].copy()
elif date_mode == "Latest date only":
    latest = view["_date"].max(); v = view[view["_date"].eq(latest)]
elif date_mode == "Last 3 days":
    v = view[view["_date"] >= (today - pd.Timedelta(days=3))]
else:
    v = view

if sport:
    v = v[_as_str(v.get("sport", "")).str.lower().isin(sport)]
if markets:
    v = v[v["market_norm"].isin(markets)]

# Optionally require model rows only
if has_model_only:
    v = v[v["p_model_use"].notna()]

# âœ… like only if model exists AND thresholds pass
like_mask = (
    v["p_model_use"].notna() &
    (pd.to_numeric(v["ev/$1"], errors="coerce").fillna(-9) >= float(min_ev)) &
    (pd.to_numeric(v["p_edge"], errors="coerce").fillna(-9) >= float(min_edge))
)
v["âœ“"] = np.where(like_mask, "âœ…", "")
if likes_only:
    v = v[like_mask]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Render
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BOOK = next((c for c in ["book","sportsbook","book_name","shop"] if c in v.columns), "book")
cols = [c for c in [
    "âœ“","game_id","market_norm","side","house_odds","house_book",BOOK,"line","odds",
    "implied_p(odds)","p_model_use","p_edge","ev/$1","_date"
] if c in v.columns]

st.dataframe(v[cols].reset_index(drop=True), use_container_width=True, height=560)
st.caption(f"Loaded: {edges_path} Â· exports root: {root_path} Â· rows={len(v):,} Â· cols={len(v.columns)}")
st.download_button("Download filtered CSV",
                   data=v[cols].to_csv(index=False).encode("utf-8"),
                   file_name="picks_live_autoload.csv", mime="text/csv")

