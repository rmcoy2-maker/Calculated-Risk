from __future__ import annotations
import os, time
from pathlib import Path
import numpy as np
import pandas as pd
import streamlit as st

# ---------- io_paths (with robust fallbacks) ----------
try:
    from lib.io_paths import (
        autoload_edges,
        clear_loader_cache,
        find_exports_dir,
        _file_mtime,
        LIVE_FILENAME,           # may not exist in older builds
    )
except Exception:
    # Minimal fallbacks so page still runs
    LIVE_FILENAME = "lines_live.csv"

    @st.cache_data(ttl=30, show_spinner=False)
    def _read_csv_safe(p: Path) -> pd.DataFrame:
        try:
            return pd.read_csv(p, low_memory=False, encoding="utf-8-sig")
        except Exception:
            return pd.DataFrame()

    def find_exports_dir() -> Path:
        for cand in [
            Path(os.environ.get("EDGE_EXPORTS_DIR", "")),
            Path("exports"),
            Path.cwd() / "exports",
        ]:
            if cand and Path(cand).exists():
                return Path(cand)
        return Path.cwd()

    def _file_mtime(p: Path | str | None) -> float | None:
        if not p:
            return None
        p = Path(p)
        try:
            return p.stat().st_mtime
        except Exception:
            return None

    _CACHE = {"df": None, "path": None, "root": None}
    def clear_loader_cache():
        _CACHE.update({"df": None, "path": None, "root": None})

    def autoload_edges(with_caption: bool = True):
        root = find_exports_dir()
        env_path = os.environ.get("EDGE_SOURCE_FILE")
        candidates = []
        if env_path:
            p = Path(env_path)
            candidates.append(p if p.is_absolute() else (Path.cwd() / env_path))
        candidates += [
            root / "edges_graded_full.csv",
            root / "edges_graded_plus.csv",
            root / "edges_graded.csv",
            root / "edges.csv",
            root / LIVE_FILENAME,  # last resort
        ]
        for p in candidates:
            if p.exists() and p.stat().st_size > 0:
                df = _read_csv_safe(p)
                if not df.empty:
                    if with_caption:
                        st.caption(
                            f"Loaded: {p} Â· exports root: {root} Â· rows={len(df):,} Â· cols={len(df.columns)}"
                        )
                    return df, str(p), str(root)
        if with_caption:
            st.caption("Loaded: â€” Â· exports root: {root} Â· rows=0 Â· cols=0")
        return pd.DataFrame(), None, str(root)

# ---------- enrich helpers ----------
try:
    from lib.enrich import add_probs_and_ev, attach_teams
except Exception:
    # graceful fallbacks: pass-through if library missing
    def attach_teams(df: pd.DataFrame) -> pd.DataFrame: return df
    def add_probs_and_ev(df: pd.DataFrame) -> pd.DataFrame: return df

st.set_page_config(page_title="Data Diagnostics", page_icon="ğŸ§ª", layout="wide")
st.title("Data Diagnostics")

# --- actions ---
lc1, lc2 = st.columns([1,4])
with lc1:
    if st.button("Refresh data", type="primary"):
        clear_loader_cache()
        st.rerun()

# --- load ---
df, df_path, root_path = autoload_edges(with_caption=True)
enriched = add_probs_and_ev(attach_teams(df.copy()))

# --- quick stats helpers ---
def _first(df: pd.DataFrame, names: tuple[str, ...]) -> str | None:
    low = {c.lower(): c for c in df.columns}
    for n in names:
        if n in low:
            return low[n]
    return None

ALT_ODDS = ("odds","american","price","price_american","american_odds")
ALT_PWIN = ("p_win","p_model","prob","model_p","win_prob","p","prob_win")
ALT_BOOK = ("book","sportsbook","bk")
ALT_MKT  = ("market","bet_type","wager_type")
ALT_SIDE = ("side","selection")
ALT_GID  = ("game_id","ref","gid","game")

odds_col = _first(enriched, ALT_ODDS)
p_col    = _first(enriched, ALT_PWIN)

p_series = pd.to_numeric(
    enriched[p_col], errors="coerce"
) if p_col else pd.to_numeric(enriched.get("p_model_use", np.nan), errors="coerce")

rows_total = len(enriched)
rows_with_odds = int(pd.to_numeric(enriched.get(odds_col, np.nan), errors="coerce").notna().sum()) if odds_col else 0
rows_with_p = int(p_series.notna().sum())

# ensure EV is present (compute it if missing)
def _payout_from_american(o):
    try:
        o = float(o)
    except Exception:
        return np.nan
    if o > 0:  return o/100.0
    if o < 0:  return 100.0/abs(o)
    return np.nan

if "ev_$1" not in enriched.columns and odds_col and rows_with_p:
    enriched["ev_$1"] = p_series * enriched[odds_col].map(_payout_from_american) - (1 - p_series)

rows_pos_ev = int(pd.to_numeric(enriched.get("ev_$1", np.nan), errors="coerce").ge(0).sum())

m1, m2, m3, m4 = st.columns(4)
m1.metric("Rows", f"{rows_total:,}")
m2.metric("With odds", f"{rows_with_odds:,}")
m3.metric("With probability", f"{rows_with_p:,}")
m4.metric("EV â‰¥ 0", f"{rows_pos_ev:,}")

# --- file presence in /exports ---
st.subheader("Exports directory & source resolution")
exp = find_exports_dir()
candidates = [
    "edges_graded_full.csv",
    "edges_graded_plus.csv",
    "edges_graded.csv",
    "edges.csv",
    LIVE_FILENAME,
]
info = []
for name in candidates:
    path = exp / name
    exists = path.exists()
    size = path.stat().st_size if exists else 0
    mtime = _file_mtime(path) if exists else None
    mt = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(mtime)) if mtime else ""
    info.append({
        "file": name,
        "exists": "yes" if exists else "no",
        "size_bytes": size,
        "last_write": mt,
        "full_path": str(path if exists else ""),
    })
st.dataframe(pd.DataFrame(info), use_container_width=True, height=220)

st.caption(
    f"Repo root: `{root_path or 'â€”'}` Â· exports dir: `{exp}` Â· "
    f"EDGE_SOURCE_FILE: `{os.environ.get('EDGE_SOURCE_FILE','(not set)')}` Â· "
    f"Loaded file: `{df_path or 'â€”'}`"
)

# --- detected columns ---
st.subheader("Detected columns")
det = {
    "game_id": _first(enriched, ALT_GID),
    "market":  _first(enriched, ALT_MKT),
    "side":    _first(enriched, ALT_SIDE),
    "book":    _first(enriched, ALT_BOOK),
    "odds":    odds_col,
    "p_win":   p_col,
}
st.json(det)

# --- sample views ---
st.subheader("Sample rows (raw)")
st.dataframe(df.head(50), use_container_width=True)

st.subheader("Sample rows (enriched: teams, p_model_use, EV, fair odds)")
show_cols = [
    det["game_id"] or "game_id",
    "home_team","away_team",
    det["market"] or "market",
    det["side"] or "side",
    det["book"] or "book",
    det["odds"] or "odds",
    det["p_win"] or "p_win",
    "p_model_use","computer_fair_odds","ev_$1",
]
exists = [c for c in show_cols if c in enriched.columns]
st.dataframe(enriched[exists].head(200), use_container_width=True)

with st.expander("How loading works", expanded=False):
    st.markdown(
        """
**Priority order** for the file loaded on every page:
1) `$EDGE_SOURCE_FILE` if set (absolute or relative to repo root)  
2) `edges_graded_full.csv` â†’ `edges_graded_plus.csv` â†’ `edges_graded.csv` â†’ `edges.csv`  
3) `lines_live.csv` (fallback)

- If the chosen file lacks a model probability, pages derive a fallback probability from *implied odds*.
- Use a graded file with a real `p_win` column for meaningful **EV** and **edges**.
- Click **Refresh data** to clear cache after dropping in new exports.
"""
    )

