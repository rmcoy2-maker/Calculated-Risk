from __future__ import annotations
import streamlit as st
from app.lib.auth import login, show_logout
# === Auth (auto-injected) ===
import streamlit as st  # ensured
from app.lib.auth import login, show_logout

auth = login(required=False)   # or required=True for protected pages
if not auth.authenticated:
    st.info("You are in read-only mode.")
show_logout()  # sidebar logout
# === /Auth (auto-injected) ===
from __future__ import annotations

# --- import bootstrap so 'app' package is importable when run from anywhere ---
import sys, os
from pathlib import Path
_HERE = Path(__file__).resolve()
_SERVING_UI = _HERE.parents[2]  # .../serving_ui
if str(_SERVING_UI) not in sys.path:
    sys.path.insert(0, str(_SERVING_UI))
# -----------------------------------------------------------------------------
import streamlit as st
import streamlit as st
st.set_page_config(page_title='20 Settled', page_icon='ðŸ“ˆ', layout='wide')

import streamlit as st

import streamlit as st


import streamlit as st


import os, time, math
from pathlib import Path
from typing import List, Optional, Dict
import numpy as np
import pandas as pd
import streamlit as st
# --- diagnostics import (robust) ---
try:
    from app.utils.diagnostics import mount_in_sidebar
except ModuleNotFoundError:
    try:
        import sys
        from pathlib import Path as _efP
        # add repo/serving_ui to sys.path so 'app' is importable
        sys.path.append(str(_efP(__file__).resolve().parents[3]))
        from app.utils.diagnostics import mount_in_sidebar
    except Exception:
        try:
            # fallback if pages run with CWD=app
            from utils.diagnostics import mount_in_sidebar
        except Exception:
            def mount_in_sidebar(page_name: str):
                return None
# --- /diagnostics import (robust) ---

TZ = "America/New_York"

def _exports_dir() -> Path:
    env = os.environ.get("EDGE_EXPORTS_DIR", "").strip()
    if env:
        p = Path(env); p.mkdir(parents=True, exist_ok=True); return p
    here = Path(__file__).resolve()
    for up in [here.parent] + list(here.parents):
        if up.name.lower() == "edge-finder":
            p = up / "exports"; p.mkdir(parents=True, exist_ok=True); return p
    p = Path.cwd() / "exports"; p.mkdir(parents=True, exist_ok=True); return p

def _age_str(p: Path) -> str:
    try:
        secs = int(time.time() - p.stat().st_mtime)
        return f"{secs}s" if secs < 60 else f"{secs//60}m"
    except Exception:
        return "n/a"

_ALIAS = {
    "REDSKINS": "COMMANDERS", "WASHINGTON": "COMMANDERS", "FOOTBALL": "COMMANDERS",
    "OAKLAND": "RAIDERS", "LV": "RAIDERS", "LAS": "RAIDERS", "VEGAS": "RAIDERS",
    "SD": "CHARGERS", "STL": "RAMS",
}

def _nickify(series: pd.Series) -> pd.Series:
    s = series.astype("string").fillna("").str.upper()
    s = s.str.replace(r"[^A-Z0-9 ]+", "", regex=True).str.strip().replace(_ALIAS)
    return s.str.replace(r"\s+", "_", regex=True)

def _best_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    low = {c.lower(): c for c in df.columns}
    for c in candidates:
        if c.lower() in low: return low[c.lower()]
    return None

def _ensure_nicks(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty: return df
    home_c = _best_col(df, ["_home_nick","home_nick","home","home_team","Home","HOME","team_home"])
    away_c = _best_col(df, ["_away_nick","away_nick","away","away_team","Away","AWAY","team_away"])
    if home_c is None: df["_home_nick"] = pd.Series([""]*len(df), dtype="string")
    else: df["_home_nick"] = _nickify(df[home_c].astype("string"))
    if away_c is None: df["_away_nick"] = pd.Series([""]*len(df), dtype="string")
    else: df["_away_nick"] = _nickify(df[away_c].astype("string"))
    return df

def _norm_market(m) -> str:
    m = (str(m) or "").strip().lower()
    if m in {"h2h", "ml", "moneyline", "money line"}: return "H2H"
    if m.startswith("spread") or m in {"spread", "spreads"}: return "SPREADS"
    if m.startswith("total")  or m in {"total", "totals"}:  return "TOTALS"
    return m.upper()

def _odds_to_decimal(o: pd.Series) -> pd.Series:
    o = pd.to_numeric(o, errors="coerce")
    return np.where(o > 0, 1 + (o / 100.0),
           np.where(o < 0, 1 + (100.0 / np.abs(o)), np.nan))

def _ensure_date_iso(df: pd.DataFrame, candidates: List[str]) -> pd.DataFrame:
    if len(df) == 0: return df
    for c in candidates:
        if c in df.columns:
            s = pd.to_datetime(df[c], errors="coerce", utc=True)
            df["_date_iso"] = s.dt.tz_convert(TZ).dt.strftime("%Y-%m-%d")
            break
    if "_date_iso" not in df.columns:
        df["_date_iso"] = pd.Series(pd.NA, index=df.index, dtype="string")
    return df

def latest_batch(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty: return df
    for col in ["_snapshot_ts_utc","snapshot_ts_utc","snapshot_ts","_ts","ts"]:
        if col in df.columns:
            ts = pd.to_datetime(df[col], errors="coerce", utc=True)
            last = ts.max()
            return df[ts == last].copy()
    return df

def within_next_week(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty: return df
    if "_date_iso" not in df.columns: return df
    d = pd.to_datetime(df["_date_iso"], errors="coerce", utc=True).dt.tz_convert(TZ)
    today = pd.Timestamp.now(tz=TZ).normalize()
    end   = today + pd.Timedelta(days=7)
    return df[(d >= today) & (d <= end)].copy()

def refresh_button(key: Optional[str] = None):
    if st.button("ðŸ”„ Refresh data", key=key or f"refresh_{__name__}"):
        try: st.cache_data.clear()
        except Exception: pass
        st.rerun()

def _latest_csv(paths: list[Path]) -> Optional[Path]:
    paths = [p for p in paths if p and p.exists()]
    if not paths: return None
    return max(paths, key=lambda p: p.stat().st_mtime)

@st.cache_data(ttl=60)
def load_live() -> tuple[pd.DataFrame, Path]:
    exp = _exports_dir()
    cand = [exp / "lines_live.csv", exp / "lines_live_latest.csv"]
    p = _latest_csv(cand) or cand[0]
    df = pd.read_csv(p, low_memory=False, encoding="utf-8-sig") if p.exists() else pd.DataFrame()
    return df, p

@st.cache_data(ttl=60)
def load_open_close() -> tuple[pd.DataFrame, Path]:
    exp = _exports_dir()
    cand = [exp/"lines_open_close.csv", exp/"lines_open_close_latest.csv"]
    p = _latest_csv(cand) or cand[0]
    df = pd.read_csv(p, low_memory=False, encoding="utf-8-sig") if p.exists() else pd.DataFrame()
    return df, p

@st.cache_data(ttl=60)
def load_edges() -> tuple[pd.DataFrame, Path]:
    exp = _exports_dir()
    names = ["edges_standardized.csv","edges_graded_full_normalized_std.csv","edges_graded_full.csv","edges_normalized.csv","edges_master.csv"]
    paths = [exp/n for n in names]
    p = _latest_csv(paths) or paths[0]
    df = pd.read_csv(p, low_memory=False, encoding="utf-8-sig") if p.exists() else pd.DataFrame()
    return df, p

diag = mount_in_sidebar("20_Settled")
st.title("Settled â€” Results")
refresh_button(key="refresh_20_settled")

from tools.lib_settlement import settle_bets
from lib.join_scores import attach_scores

@st.cache_data(ttl=60)
def load_scores() -> tuple[pd.DataFrame, Path]:
    exp = _exports_dir(); p = exp / "scores_1966-2025.csv"
    df = pd.read_csv(p, low_memory=False, encoding="utf-8-sig") if p.exists() else pd.DataFrame()
    return df, p

edges, epath = load_edges()
scores, spath = load_scores()
st.caption(f"Edges: `{epath}` Â· rows={len(edges):,}")
st.caption(f"Scores: `{spath}` Â· rows={len(scores):,}")

# Coerce Season/Week types to avoid merge dtype mismatch
for df in (edges, scores):
    for c in ["Season","Week"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce").astype("Int64")

if edges.empty:
    st.warning("No edges to settle."); st.stop()

try:
    settled = settle_bets(edges)  # 1-arg variant
except TypeError:
    settled = settle_bets(edges, scores)  # 2-arg variant
except Exception:
    # Fallback: attach scores first then try 1-arg settlement if available
    try:
        joined = attach_scores(edges.copy(), scores.copy())
        settled = settle_bets(joined)
    except Exception as e:
        st.exception(e); st.stop()

st.sidebar.header("Filters")
only_scored = st.sidebar.checkbox("Only scored bets", value=True)
result_pick = st.sidebar.multiselect("Result", ["WIN","LOSS","PUSH","VOID"], default=[])

view = settled.copy()
if only_scored and "_has_scores" in view.columns:
    view = view[view["_has_scores"]]
if result_pick:
    view = view[view.get("_result","").isin(result_pick)]

st.write(f"Showing {len(view):,} rows"); st.dataframe(view, use_container_width=True, hide_index=True)
if st.button("Export settled to exports/settled.csv"):
    out = _exports_dir() / "settled.csv"; view.to_csv(out, index=False, encoding="utf-8-sig"); st.success(f"Saved â†’ {out}")

# --- _EF_DIAG_SNAPSHOT_ (auto-added) ---
try:
    import pandas as _ef_pd
    from pathlib import Path as _ef_Path
    _ef = locals().get("diag", None)
    if _ef:
        for _nm in ("edges_p","live_p","oc_path","edges_path","live_path","scores_path","scores_p","epath","spath","_lines_p","_edges_p"):
            _p = locals().get(_nm, None)
            if _p:
                try: _ef.check_file(_ef_Path(str(_p)), required=False, label=_nm)
                except Exception: pass
        for _dfn in ("edges","live","oc","scores","joined","view"):
            _df = locals().get(_dfn, None)
            try:
                if isinstance(_df, _ef_pd.DataFrame):
                    _ef.log_df(_df, _dfn)
            except Exception:
                pass
except Exception:
    pass
# --- /_EF_DIAG_SNAPSHOT_ ---

# --- _EF_SETTLE_BLOCK_ (auto-added) ---
import pandas as _efpd
from pathlib import Path as _efP
from tools.lib_settlement import settle_bets

try:
        diag = mount_in_sidebar("20_Settled")
except Exception:
    pass

_ex = _efP(__file__).resolve().parents[2] / "exports"
edges_guess = None
for nm in ("edges_graded_full_normalized_std.csv","edges_normalized.csv","edges.csv","edges_master.csv"):
    p = _ex / nm
    if p.exists() and p.stat().st_size > 0:
        edges_guess = p; break
scores_p = _ex / "scores_1966-2025.csv"

c1, c2 = st.columns([2,1])
with c1:
    edges_p = st.text_input("Edges CSV", str(edges_guess) if edges_guess else str(_ex/"edges.csv"))
    scores_path = st.text_input("Scores CSV", str(scores_p))
with c2:
    st.caption("Both files must exist. Scores should have HomeScore/AwayScore.")

do_settle = st.button("âœ… Settle Now")
if do_settle:
    try:
        e = _efpd.read_csv(edges_p, low_memory=False)
        s = _efpd.read_csv(scores_path, low_memory=False)
        if "diag" in locals():
            diag.check_file(edges_p, label="edges_p", required=True)
            diag.check_file(scores_path, label="scores_path", required=True)
            diag.log_df(e, "edges")
            diag.log_df(s, "scores")

        settled = settle_bets(e, s)
        out_p = _ex / "settled.csv"
        settled.to_csv(out_p, index=False)
        st.success(f"Settled {len(settled):,} rows â†’ {out_p}")
        st.dataframe(settled.head(200), use_container_width=True)
    except Exception as err:
        st.error(f"Settlement failed: {err}")
# --- /_EF_SETTLE_BLOCK_ ---







