# tools/train_parlay.py  (fixed)
import argparse, os, joblib
import numpy as np
import pandas as pd

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score

def load_edges(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    df.columns = [c.strip().lower() for c in df.columns]
    return df

def coerce_numeric(df: pd.DataFrame, cols):
    for c in cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
        else:
            df[c] = np.nan
    return df

def main():
    ap = argparse.ArgumentParser(description="Train parlay propensity model from graded edges.")
    ap.add_argument("--edges", required=True)
    ap.add_argument("--out",   required=True, help="Output dir for model artifacts")
    ap.add_argument("--min-season", type=int, default=2017)
    args = ap.parse_args()

    os.makedirs(args.out, exist_ok=True)

    df = load_edges(args.edges)
    if df.empty:
        raise SystemExit("edges_graded.csv is empty. Run the grader first and verify it wrote rows.")

    # Filter by season if present
    if "season" in df.columns:
        df = df[pd.to_numeric(df["season"], errors="coerce") >= args.min_season].copy()

    # ---- FIX: build target safely without using 'or' on a Series ----
    if "result" in df.columns:
        # Derive target: normalize to win/lose, drop pushes/unknown
res = df.get("result", pd.Series([None]*len(df))).astype(str).str.strip().str.lower()
# Map common encodings to canonical text first (optional: keep simple for now)
# If your data already uses "win"/"lose", this is enough:
mask_valid = res.isin(["win","lose"])
df = df[mask_valid].copy()
if df.empty:
    raise SystemExit("No trainable rows (only pushes/unknown).")
y = (df["result"].astype(str).str.lower() == "win").astype(int)n_win = int((y == 1).sum())
n_lose = int((y == 0).sum())
if len(set(y.tolist())) < 2:
    raise SystemExit(f"Only one class present in labels: wins={n_win}, loses={n_lose}. "
                     f"Add more graded data (both wins and losses) or widen --min-season.")

# Features â€“ numeric vs categorical
num_cols = ["odds","line","p_win","dec_comb","legs","parlay_stake","stake","week_num"]
cat_cols = ["market","ref","sport","league"]

df = coerce_numeric(df, num_cols)
for c in cat_cols:
    if c not in df.columns:
        df[c] = ""

X = df[num_cols + cat_cols].copy()# Pipeline
    num_pipe = Pipeline(steps=[("impute", SimpleImputer(strategy="median"))])
    cat_pipe = Pipeline(steps=[
        ("impute", SimpleImputer(strategy="most_frequent")),
        ("oh", OneHotEncoder(handle_unknown="ignore", min_frequency=5)),
    ])
    pre = ColumnTransformer(
        transformers=[
            ("num", num_pipe, num_cols),
            ("cat", cat_pipe, cat_cols),
        ]
    )

    clf = LogisticRegression(max_iter=200, solver="lbfgs")
    pipe = Pipeline(steps=[("pre", pre), ("clf", clf)])

    pipe.fit(X, y)

    # Metric (best-effort)
    try:
        prob = pipe.predict_proba(X)[:, 1]
        auc = roc_auc_score(y, prob)
    except Exception:
        auc = float("nan")

    joblib.dump(pipe, os.path.join(args.out, "parlay_model.joblib"))
    pd.Series({
        "rows": int(len(df)),
        "win_rate": float(y.mean()),
        "auc": auc,
        "min_season": args.min_season,
        "num_cols": num_cols,
        "cat_cols": cat_cols,
    }).to_json(os.path.join(args.out, "meta.json"), indent=2)

    print(f"Saved model to {args.out}\\parlay_model.joblib  (rows={len(df)}, AUC={auc:.3f})")

if __name__ == "__main__":
    main()





